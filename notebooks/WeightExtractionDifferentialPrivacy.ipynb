{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "tff.backends.reference.set_reference_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from federated.data.data_preprocessing import load_data, create_unbalanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLIENTS=5\n",
    "CLIENT_EPOCHS=10\n",
    "BATCH_SIZE=32\n",
    "NUM_EXAMPLES_PER_USER = 20_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_client_data, test_client_data = load_data(normalized=True, data_selector=create_unbalanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_ecg(source, client):\n",
    "    output_sequence = []\n",
    "    data = source[f\"client_{client}\"]\n",
    "    all_samples = [i for i, y in enumerate(data[1])]\n",
    "    for i in range(0, min(len(all_samples), NUM_EXAMPLES_PER_USER), BATCH_SIZE):\n",
    "        batch_samples = all_samples[i:i + BATCH_SIZE]\n",
    "        output_sequence.append({\n",
    "            \"x\": np.array([data[0][i] for i in batch_samples], dtype=np.float32),\n",
    "            \"y\": np.array([np.where(data[1][i]==1)[0][0] for i in batch_samples], dtype=np.int32)\n",
    "        })\n",
    "    return output_sequence\n",
    "\n",
    "federated_train_data = [get_data_for_ecg(train_client_data, client) for client in range(1, 6)]\n",
    "\n",
    "federated_test_data = [get_data_for_ecg(train_client_data, client) for client in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SPEC = collections.OrderedDict(\n",
    "    x=tf.TensorSpec(shape=[None, 186], dtype=tf.float32),\n",
    "    y=tf.TensorSpec(shape=[None], dtype=tf.int32))\n",
    "BATCH_TYPE = tff.to_type(BATCH_SPEC)\n",
    "\n",
    "str(BATCH_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SPEC = collections.OrderedDict(\n",
    "    weights=tf.TensorSpec(shape=[186, 5], dtype=tf.float32),\n",
    "    bias=tf.TensorSpec(shape=[5], dtype=tf.float32))\n",
    "MODEL_TYPE = tff.to_type(MODEL_SPEC)\n",
    "\n",
    "print(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def forward_pass(model, batch):\n",
    "    predicted_y = tf.nn.softmax(\n",
    "        tf.matmul(batch['x'], model['weights']) + model['bias'])\n",
    "    return -tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            tf.one_hot(batch['y'], 5) * tf.math.log(predicted_y), axis=[1]))\n",
    "\n",
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "def batch_loss(model, batch):\n",
    "    return forward_pass(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = collections.OrderedDict(\n",
    "    weights=np.zeros([186, 5], dtype=np.float32),\n",
    "    bias=np.zeros([5], dtype=np.float32))\n",
    "\n",
    "sample_batch = federated_train_data[4][-1]\n",
    "\n",
    "batch_loss(initial_model, sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
    "def batch_train(initial_model, batch, learning_rate):\n",
    "    # Define a group of model variables and set them to `initial_model`. Must\n",
    "    # be defined outside the @tf.function\n",
    "    model_vars = collections.OrderedDict([\n",
    "        (name, tf.Variable(name=name, initial_value=value))\n",
    "        for name, value in initial_model.items()\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "    @tf.function\n",
    "    def _train_on_batch(model_vars, batch):\n",
    "        # Perform one step gradient descent using loss from `batch_loss`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = forward_pass(model_vars, batch)\n",
    "        grads = tape.gradient(loss, model_vars)\n",
    "        optimizer.apply_gradients(\n",
    "            zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
    "        return model_vars\n",
    "\n",
    "    return _train_on_batch(model_vars, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)\n",
    "\n",
    "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
    "def local_train(initial_model, learning_rate, all_batches):\n",
    "\n",
    "    # Mapping function to apply to each batch\n",
    "    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "    def batch_fn(model, batch):\n",
    "        return batch_train(model, batch, learning_rate)\n",
    "    \n",
    "    return tff.sequence_reduce(all_batches, initial_model, batch_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locally_trained_model = local_train(initial_model, 0.1, federated_train_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)\n",
    "def local_eval(model, all_batches):\n",
    "    return tff.sequence_sum(\n",
    "        tff.sequence_map(\n",
    "            tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),\n",
    "            all_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('initial_model loss =', local_eval(initial_model,\n",
    "                                          federated_train_data[4]))\n",
    "\n",
    "print('locally_trained_model loss =',\n",
    "      local_eval(locally_trained_model, federated_train_data[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('initial_model loss =', local_eval(initial_model,\n",
    "                                          federated_train_data[0]))\n",
    "\n",
    "print('locally_trained_model loss =',\n",
    "      local_eval(locally_trained_model, federated_train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_MODEL_TYPE = tff.type_at_server(MODEL_TYPE)\n",
    "CLIENT_DATA_TYPE = tff.type_at_clients(LOCAL_DATA_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)\n",
    "def federated_eval(model, data):\n",
    "    return tff.federated_mean(\n",
    "        tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('initial_model loss =', federated_eval(initial_model,\n",
    "                                          federated_train_data))\n",
    "\n",
    "print('locally_trained_model loss =',\n",
    "      federated_eval(locally_trained_model, federated_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_FLOAT_TYPE = tff.type_at_server(tf.float32)\n",
    "\n",
    "@tff.federated_computation(\n",
    "    SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)\n",
    "def grab_all_models(model, learning_rate, data):\n",
    "  return tff.federated_collect(\n",
    "      tff.federated_map(\n",
    "          local_train,\n",
    "          [tff.federated_broadcast(model),\n",
    "           tff.federated_broadcast(learning_rate),\n",
    "           data]))\n",
    "\n",
    "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE,\n",
    "                           CLIENT_DATA_TYPE)\n",
    "def federated_train(model, learning_rate, data):\n",
    "    return tff.federated_mean(\n",
    "        tff.federated_map(local_train, [\n",
    "            tff.federated_broadcast(model),\n",
    "            tff.federated_broadcast(learning_rate), data\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = tf.keras.models.load_model(\"../history/logdir/fedavg_linear_dp_v2\")\n",
    "weights = keras_model.layers[1].get_weights()[0]\n",
    "biases = keras_model.layers[1].get_weights()[1]\n",
    "\n",
    "print(weights.shape)\n",
    "print(biases.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = collections.OrderedDict(\n",
    "    weights=weights,\n",
    "    bias=biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = grab_all_models(model, 0.1, federated_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "illness = [\"Normal beats\", \"Supraven.\", \"Ventricular\", \"Fusion\", \"Unknown\"]\n",
    "#fig, axs = plt.subplots(5, 2, figsize=(20,20))\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(5):\n",
    "    model = models[i]\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.plot(model[\"weights\"][:, 1])\n",
    "    plt.title(f\"Client {i+1}, Supraventricular Beats\")\n",
    "\n",
    "plt.savefig(f\"images/weight_extraction_supra_dp.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}