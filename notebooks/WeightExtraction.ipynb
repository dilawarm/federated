{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "S = 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import collections\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from federated.data.mitbih_data_preprocessing import get_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLIENTS=5\n",
    "CLIENT_EPOCHS=10\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'create_unbalanced_data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-526155d765ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mtrain_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCLIENT_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mnumber_of_clients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUMBER_OF_CLIENTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mdata_selector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_unbalanced_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0msave_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_unbalanced_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_X, train_y = get_datasets(\n",
    "        train_batch_size=BATCH_SIZE,\n",
    "            centralized=False,\n",
    "            normalized=True,\n",
    "            train_epochs=CLIENT_EPOCHS,\n",
    "            number_of_clients=NUMBER_OF_CLIENTS,\n",
    "            data_selector=create_unbalanced_data,\n",
    "            save_data=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def forward_pass(model, batch):\n",
    "    predicted_y = tf.nn.softmax(tf.matmul(batch['x'], model['weights']) + model['bias'])\n",
    "    return -tf.reduce_mean(tf.reduce_sum(tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.tf_comfederated_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)\n",
    "def batch_train(initial_model, batch, lr):\n",
    "\n",
    "    model_vars = collections.OrderedDict([\n",
    "        (name, tf.Variable(name=name, initial_value=value))\n",
    "        for name, value in initial_model.items()\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "    @tf.function\n",
    "    def train_on_batch(model_vars, batch):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = forward_pass(model_vars, batch)\n",
    "        grads = tape.gradient(loss, model_vars)\n",
    "        optimizer.apply_gradients(zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))\n",
    "        return model_vars\n",
    "    return train_on_batch(model_vars, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)\n",
    "def local_train(initial_model, lr, batches)\n",
    "    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)\n",
    "    def batch_function(model, batch):\n",
    "        return batch_train(model, batch, lr)\n",
    "    return tff.sequence_reduce(batches, initial_model, batch_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tff.federated_computation(SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)\n",
    "def grab_all_models(model, lr, data):\n",
    "    return tff.federated_collect(tff.federated_map(\n",
    "        \n",
    "    ))"
   ]
  }
 ]
}